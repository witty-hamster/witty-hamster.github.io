
## 一、MySQL 数据库

### Q001：数据库事务的四大特性（ACID）分别是什么？

- **回答方式一（学术流）**：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。
    
- **回答方式二（白话流）**：要么全做要么不做；逻辑要对；大家干活别互相干扰；做完了就得写死在硬盘上。

### Q002：MySQL 在 RR（可重复读）隔离级别下，是如何通过 Next-Key Lock 解决幻读问题的？

- **回答方式一（锁范围流）**：Next-Key Lock = Record Lock（行锁） + Gap Lock（间隙锁）。它不仅锁住索引记录，还锁住记录之间的间隙，防止其他事务在该范围内插入新数据，从而在逻辑上解决了幻读。
    
- **回答方式二（区域封锁流）**：不仅要把家里的门锁上（行锁），还要把家门口的路也封了（间隙锁）。这样别人不仅进不去你家，也没法在你家门口盖新房，你抬头看窗外永远还是原来的样子。

### Q003：MySQL 如果发生“深分页”查询（如 limit 1000000, 10），除了子查询优化，还有什么基于“延迟关联”的方法？

- **回答方式一（索引覆盖流）**：先通过覆盖索引只查出主键 ID（此时不需要回表，极快），再通过这些 ID 关联原表查询具体字段。这大大减少了引擎层扫描并丢弃无效数据页的 IO 开销。
    
- **回答方式二（找人效率流）**：不要让警察（数据库）去翻 100 万个人的详细档案（回表）只为了找第 100 万零一个。让他先翻名单（索引）数出那几个人的编号，然后再去档案柜里拿那几个人的详细档案。

### Q004：为什么 B+ 树索引 3 层就能撑起千万级数据？如何计算？

- **回答方式一（数据建模流）**：非叶子节点存键值和指针。假设页 16KB，指针+键值约 14B，一个节点可存 1100+ 指针。3 层树的叶子节点数超过 $1100^2$，按每行记录 1KB 算，总承载量可达 2000 万条左右。
    
- **回答方式二（几何倍增流）**：因为分叉极多，像一棵茂盛的树。每一层都能指引成千上万个方向。只要“路标”足够密，三步之内就能找到全中国任何一户人家。

### Q005：MySQL 索引的底层结构为什么选 B+ 树，而不是红黑树或 B 树？

- **简答：** B+ 树更矮胖，磁盘 IO 次数少；叶子节点通过双向链表连接，范围查询效率极高。
    
- **深度解析：** 数据库性能瓶颈在于磁盘 IO。红黑树在数据量大时高度过高；B 树每个节点都存 Data，导致单个页能存的索引键变少，树变高。B+ 树非叶子节点只存 Key，单次 IO 能加载更多索引，且由于 Data 全在叶子节点，查询延迟非常稳定。

### Q006：什么是“覆盖索引（Covering Index）”？它为什么能优化查询？

- **简答：** 查询的列全在索引中，不需要回表。
    
- **深度解析：** 正常非聚簇索引查询需要先找到主键 ID，再回主键索引找行记录（回表）。如果建立复合索引 `(name, age)`，执行 `SELECT age FROM table WHERE name = 'xxx'`，引擎直接从索引页取值返回。在百万级数据量下，减少回表能显著降低磁盘 IO。

### Q007：如何解决 MySQL 的深分页（Limit 1000000, 10）查询变慢的问题？

- **简答：** 避免偏移，使用标签偏移（Seek Method）或子查询优化。
    
- **深度解析：** `LIMIT` 本质是抛弃掉前面的百万行。**优化方案：** 1. **延迟关联：** 先通过子查询找到主键，再 Join 原表，减少回表次数。 2. **游标式查询：** 记录上次查询的最大 ID，`WHERE id > last_id LIMIT 10`。这在分库分表环境下是唯一可行的深分页方案。

### Q008：什么是 InnoDB 的“意向锁（Intention Lock）”？它的作用是什么？

- **简答**：它是表级锁，分为意向共享锁（IS）和意向排他锁（IX），用于协调行锁与表锁的关系。
    
- **深度解析**：如果没有意向锁，当你尝试给一张表加表锁时，必须遍历全表检查是否有行锁，效率极低。有了意向锁，事务在给某行加锁前必须先获取表的意向锁。申请表锁时，只需检查表上的意向锁标识即可，大大提升了**并发判别效率**。

### Q009：解释一下 MySQL 的 MVCC（多版本并发控制）机制。

- **简答**：通过 `undo log` 版本链和 `Read View` 实现非阻塞读。
    
- **深度解析**：
    
    每行记录都有隐藏列（事务 ID、回滚指针）。执行快照读时，系统生成一个 Read View（包含当前活跃事务 ID）。根据对比规则，决定当前事务能看到哪个版本的历史数据。这使得 **RC（读已提交）** 和 **RR（可重复读）** 隔离级别下，读操作不需要加锁。

### Q010：Binlog、Redo Log、Undo Log 有什么区别？为什么需要两阶段提交？

- **简答**：Binlog 是归档日志（Server层），Redo Log 是奔溃恢复日志（引擎层），Undo Log 是回滚日志。
    
- **深度解析**：
    
    - **Redo Log**：WAL（Write-Ahead Logging）机制的核心，确保事务持久性。
        
    - **两阶段提交**：为了保证 Redo Log 和 Binlog 的**逻辑一致性**。如果不使用两阶段提交，可能导致数据库恢复后数据与通过 Binlog 同步出的从库数据不一致。
### Q011：什么是“幻读（Phantom Read）”？MySQL 是如何解决的？

- **简答**：同一事务内多次查询，记录行数不一致。MySQL 在 RR 级别下通过 **Next-Key Locks** 解决。
    
- **深度解析**：Next-Key Lock = 行锁 + 间隙锁（Gap Lock）。它不仅锁住记录本身，还锁住记录之间的空隙，防止其他事务在范围内插入新数据，从而在技术层面消灭了幻读。

### Q012：MySQL 如何优化死锁？

- **深度解析**：1. 设置合理的 `innodb_lock_wait_timeout`；2. 开启 `innodb_deadlock_detect` 自动回滚代价最小的事务；3. 业务层保证加锁顺序一致。

### Q013：自增主键用完了怎么办？

- **深度解析**：`int unsigned` 上限约 42 亿。如果溢出，建议使用 `bigint`。若由于分库分表导致 ID 冲突，应切换为分布式 ID 生成器。

### Q014：为什么不建议使用 `UUID` 做 MySQL 主键？

- **深度解析**：B+ 树要求主键尽可能有序。UUID 是无序的，会导致索引页频繁分裂和合并，产生大量磁盘碎片，降低写入性能。

### Q015：什么是“页分裂”和“页合并”？

- **深度解析**：当数据随机插入导致索引页满时会发生页分裂。频繁的分裂会降低填充因子。架构上推荐顺序插入。

### Q016：如何分析慢查询日志？

-  **深度解析**：使用 `mysqldumpslow` 或 `pt-query-digest`。关注 `Rows_examined`（扫描行数）与 `Rows_sent`（返回行数）的比例。

### Q017：`COUNT(*)`、`COUNT(1)`、`COUNT(col)` 哪个更快？

- **深度解析**：在 InnoDB 中，`COUNT(*)` 和 `COUNT(1)` 经过优化后基本等价。`COUNT(col)` 需判断是否为 NULL，速度最慢。

---

## 二、Redis 缓存

### Q001：Redis 常用的五种数据类型及应用场景？

- **回答方式一（概括流）**：String（计数、缓存）、Hash（对象存储）、List（队列）、Set（去重、交集）、ZSet（排行榜）。
    
- **回答方式二（场景流）**：想存验证码用 String；存用户信息用 Hash；做点赞排名用 ZSet；做共同好友功能用 Set。

### Q002：Redis 单线程为什么快？什么操作会使其“变慢”？

- **回答方式一（系统瓶颈流）**：快在纯内存操作、IO 多路复用和无锁竞争。慢在**大 Key 操作**（如 `hgetall`）或耗时命令（`keys *`），这些会阻塞单线程 Event Loop，导致后续请求排队。
    
- **回答方式二（窗口服务流）**：工作人员手速极快且不用跟别人商量（无锁），所以快。但他最怕有人让他搬一块巨大的石头（大 Key），搬石头的时候，后面办小业务的人都得等着。

### Q003：释放 Redis 锁为什么要用 Lua 脚本？脑裂情况下如何保证锁安全？

- **回答方式一（原子性流）**：Lua 保证“校验身份”和“删除锁”原子化，防止误删他人的锁。脑裂可用 Redlock（过半成功）或业务层隔离令牌（Fencing Token）解决。
    
- **回答方式二（姓名贴流）**：撕掉锁前得先看上面的名字对不对，且这个动作必须一气呵成。预防脑裂就像投票，必须得到大多数服务器的同意。

### Q004：Redis 哨兵集群选举 Leader 时，如果票数一样或发生平票，底层逻辑是如何决策的？

- **回答方式一（随机超时流）**：Sentinel 采用 Raft 协议的思想。每个 Sentinel 都有一个随机的超时时间，谁先超时谁就发起投票请求。这种随机性极大地降低了多个节点同时发起投票导致平票的概率。
    
- **回答方式二（起床闹钟流）**：就像一屋子人睡觉（平票后）。每个人定个随机闹钟，谁先醒谁就是班长（Leader）。因为大家闹钟时间不一样，所以基本不会有人同时醒来抢班长。

### Q005：高并发场景下，如何设计一个百万级 TPS 的本地缓存与 Redis 多级缓存同步方案？

- **回答方式一（通知发布流）**：本地缓存（Caffeine）支撑极高 TPS。数据变更时，通过 Redis Pub/Sub 或 MQ 广播“失效事件”，各实例收到后清理本地缓存。这种方案牺牲了短暂的强一致性，换取了极高的查询吞吐量。
    
- **回答方式二（情报网流）**：总部（Redis）存总数据，各分部（本地缓存）存副本。一旦总部改了，发个电报（MQ）给各分部：“把原来的销毁了，来我这拿新的”。这样平时大家直接在自家门口拿情报，速度最快。

### Q006：在高并发下，如何解决 Redis 缓存与数据库的“双写一致性”问题？为什么不推荐用强一致性方案？

- **回答方式一（工程流）**：常用方案是“延迟双删”或“监听 Binlog 异步删除缓存”。强一致性需要分布式锁或 2PC，这会大幅拉低系统吞吐量，在互联网高并发场景下，通常追求“最终一致性”。
    
- **回答方式二（平衡流）**：没有绝对的同步，只有尽可能小的时差。你要追求绝对一致，系统就会慢得像蜗牛；通过异步删缓存，虽然有几百毫秒数据对不上，但能保住系统不挂。

### Q007：Redis 的分布式锁如何处理“锁续期”问题？（Watchdog 机制）

- **简答：** 利用 Redisson 等工具提供的看门狗线程，定期延长未完成业务的锁有效期。
    
- **深度解析：** 分布式锁最怕业务没跑完锁过期了。Redisson 在获取锁成功后会开启一个定时任务（默认 10s 触发一次），检查业务是否还在运行，如果是则将过期时间重置为 30s。这防止了高并发下锁被误释放导致的并发安全问题。

### Q008：Redis 集群（Cluster）模式下，如何处理热点 Key？

- **简答：** 复制多份副本、本地缓存或使用高性能代理。
    
- **深度解析：** Cluster 模式根据哈希槽分配，热点 Key 会导致单台机器网卡打满。
    
    1. **多副本法：** 将热点 Key 加上后缀（如 `key_1`, `key_2`）散布到不同节点。
        
    2. **本地二级缓存：** 利用 Guava/Caffeine 在应用层挡住 90% 的流量，仅在失效时穿透到 Redis。
### Q009：Redis 的数据结构底层实现，你了解多少？

- **深度解析**：Redis 并非简单使用 C 语言原生结构，而是进行了深度优化：

	- **String**：使用 **SDS (简单动态字符串)**，预分配空间，获取长度 $O(1)$。
    
	- **List**：由 **Quicklist**（双向链表+压缩列表）组成，兼顾空间利用率和性能。
    
	- **Hash/Set/ZSet**：在元素较少时使用 **ZipList (压缩列表)**，节省连续内存；元素多时转为 **HashTable** 或 **SkipList (跳跃表)**。
    
	- **架构价值**：这种“动态转换”的设计，使 Redis 在不同数据规模下都能保持内存和速度的最优平衡。
### Q010：Redis 为什么会有“大 Key”和“热 Key”问题？如何优雅处理？

- **深度解析**：

	- **BigKey**：导致执行命令阻塞、网络拥塞、甚至是删除时的瞬时 STW。**方案**：使用 `UNLINK` 异步删除；将大字段拆分到不同的 Hash 槽。
    
	- **HotKey**：导致单分片 CPU/网卡被打满。**方案**：1. **客户端多级缓存**（Caffeine）；2. **备份 Key**（在 Key 后加随机后缀，散布到多个分片）。

### Q011：Redis 持久化 AOF 为什么会有“重写（Rewrite）”机制？

- **深度解析**：AOF 随着写操作增加会无限膨胀。重写机制不是读取旧 AOF，而是**读取当前内存中的快照**，将其转为最小指令集。例如 100 次 `INCR` 最终合并为一条 `SET`。这极大缩小了文件体积，加快了重启恢复速度。

### Q012：Redis 主从同步的“全量同步”与“增量同步”分别在什么场景发生？

- **深度解析**：

	- **全量**：首次同步或 Slave 离线时间过长（超过 `repl_backlog` 缓冲区大小）。Master 生成 RDB 发给 Slave。
    
	- **增量**：正常运行时或短时间断线。通过偏移量（Offset）从缓冲区同步差异数据，对性能影响极小。

### Q013：什么是 Redis 的“缓存污染”？如何配置 LRU/LFU 策略？

- **深度解析**：某些数据访问一次后再也不用，却长期占用内存。`maxmemory-policy` 配置：

	- **LRU (最近最少使用)**：适合有明显冷热区分的场景。
    
	- **LFU (最不经常使用)**：Redis 4.0 引入，更精准，防止偶尔被访问的冷数据挤掉真正的热数据。

### Q014：为什么 Redis Cluster 不支持跨节点的事务或 MSET？

- **简答**：因为不同 Key 经 Hash 运算后会分布在不同的 Slot（槽）上，也就是物理上存在于不同的节点，Redis 无法跨节点保证原子性。
    
- **深度解析**： Redis 的单机原子性依赖于单线程执行模型。在集群模式下，若操作跨越节点，则需要复杂的分布式锁或两阶段提交（2PC）来保证原子性，这会极大拖慢 Redis 的性能。 **架构对策**：如果业务上必须使用多键操作，可以利用 **Hash Tag**（如 `{user:123}:info` 和 `{user:123}:order`），强制让带相同 `{}` 内容的 Key 映射到同一个 Slot。

### Q015：Redis 哨兵模式下，脑裂问题如何通过 `min-slaves-to-write` 解决？

- **简答**：通过配置“至少有多少个从节点连接时才允许写入”，强制让失去多数派联系的旧 Master 停止服务。
    
- **深度解析**：
    
    当网络分区发生，旧 Master 无法与哨兵及从节点通信，但客户端若还能连接旧 Master 就会导致脑裂。通过设置 `min-slaves-to-write 1` 和 `min-slaves-max-lag 10`，当旧 Master 发现自己没有一个活跃从节点时，会拒绝写入请求。这样当分区恢复时，旧 Master 被降级为从节点同步新 Master 数据，就能最大限度减少数据丢失。

### Q016：深度对比 Redis 事务（MULTI）与 Lua 脚本的原子性差异。

- **简答**：Redis 事务不保证原子性（某条失败后续仍执行），且不支持回滚；Lua 脚本是 **严格原子** 的，整个脚本执行期间不会被其他命令插入。
    
- **深度解析**： Redis 事务仅仅是命令的队列化，如果执行期间出错（如语法错），Redis 会跳过错误的命令继续执行。而 Lua 脚本在执行时，Redis 会将其作为一个整体。**架构选型**：在涉及“读取-计算-写回”这种需要逻辑判断的原子操作（如分布式限流）时，**必须使用 Lua 脚本**。

### Q017：什么是缓存预热、缓存雪崩、缓存击穿、缓存穿透？

- **简答**：
    
    - **预热**：上线前先把热点存入缓存。
        
    - **雪崩**：大量 Key 同时失效（方案：随机过期时间）。
        
    - **击穿**：热点 Key 失效（方案：逻辑过期或互斥锁）。
        
    - **穿透**：查不存在的数据（方案：布隆过滤器）。
        
- **深度解析**：
    
    这些问题是高并发系统的命门。**雪崩**是点对面的崩溃，**击穿**是点对点的爆破。在架构设计中，必须构建**多级防御**：前端限流 + 布隆过滤器过滤无效请求 + 缓存层随机 TTL + 后端限流熔断，防止压力瞬间压垮数据库。

### Q018：Redis 6.0 引入多线程 IO，为什么核心执行指令还是单线程？

- **简答**：为了在不引入“锁”竞争的情况下，解决网络 IO 处理的瓶颈。
    
- **深度解析**： Redis 瓶颈通常在于网络处理。6.0 引入多线程来并行读取、解析协议及写回结果，但核心的**命令执行**依然在主线程串行完成。这样既利用了多核 CPU 提升 IO 吞吐，又保留了 Redis 开发简单、无并发锁竞争、原子性强的优点。

### Q019：如何实现基于 Redis 的延时队列？

- **简答**：常用 `ZSet` 实现（以时间戳为 Score），或者利用“键空间通知（Pub/Sub）”。
    
- **深度解析**： **ZSet 方案**：将任务放入 ZSet，Score 设为执行时间。客户端循环执行 `ZRANGEBYSCORE` 获取到期的任务并 `ZREM` 删除。 **键空间通知**：监听 `__keyevent@0__:expired`。但要注意，Redis 的过期删除是惰性的，**延迟可能非常大**。在架构上，如果对延迟精度要求极高，建议使用 RocketMQ 或 RabbitMQ 的原生延时队列。

### Q020：Redis 内存碎片率（mem_fragmentation_ratio）过高怎么办？

- **简答**：若比值 > 1.5，说明碎片严重。可重启 Redis 或开启 `activedefrag` 自动清理。
    
- **深度解析**： 碎片通常是由频繁更新及数据长度不一导致的。Redis 4.0+ 提供了 **Active Defragmentation** 功能，在主线程空闲时，将数据拷贝到连续的内存地址并释放旧空间。开启时需注意调节 CPU 占用限制，防止清理操作影响正常请求的延迟。

### Q021：缓存与数据库双写一致性：为什么删缓存比更新缓存更好？

- **简答**：更新缓存开销大且容易产生脏数据（并发覆盖），删缓存能保证下次读请求一定去数据库拿新值。
    
- **深度解析**：
    
    如果两个线程同时更新，由于网络延迟，可能出现“旧值覆盖新值”的脏数据。**架构金标准**：采用“先更新数据库，再删除缓存”的 **Cache-Aside 模式**，并配合“延迟双删”或“Binlog 异步删除”来兜底，确保最终一致性。

### Q022：什么是 Redis 的“旁路缓存（Cache Aside）”模式？

- **简答**：读时先读缓存，不中则读库并写缓存；写时先更数据库，再删缓存。
    
- **深度解析**： 这是分布式系统最常用的缓存模式。它的核心逻辑是将“缓存维护”的权力交给应用端。相对于 **Read/Write Through**（应用只管操作缓存，缓存层管数据库），Cache Aside 逻辑简单，对数据库没有侵入性，且通过“失效”机制大大降低了数据不一致的风险。

### Q023：Redis 线程模型：单线程如何处理数万个并发连接？

- **简答**：基于 **IO 多路复用机制（epoll）**。
    
- **深度解析**：
    
    Redis 使用一个线程监控成千上万个文件描述符。当某个连接有数据可读时，内核会通知 Redis。主线程以非阻塞方式处理这些就绪的事件，然后快速轮转。由于 Redis 所有操作都在内存，速度极快，单线程足以在微秒级处理完当前请求并切换到下一个，从而给用户营造了并发的错觉。


---

## 三、Elasticsearch

### Q001：ES 的倒排索引（Inverted Index）为什么检索速度快？

- **简答：** 它记录了单词到文档 ID 的映射，避免了全量扫描。
    
- **深度解析：** ES 内部使用了 **FST (Finite State Transducer)** 压缩词典，并利用 **SkipList (跳跃表)** 进行文档 ID 的位运算合并。即使是千万级文档的布尔查询，也能在毫秒级通过位图计算出交集。

### Q002：ES 写入数据的全过程是什么？（从 Buffer 到 Segment）

- **简答**：数据先写 Memory Buffer 和 Translog，每隔 1s 通过 Refresh 变为 Segment 并进入 OS Cache，此时数据可见（近实时），最后通过 Flush 持久化到磁盘。

- **深度解析**：

	1. **Memory Buffer**：数据先入内存缓冲区。
    
	2. **Refresh**：默认 1s，将 Buffer 刷入 **OS Cache** 生成 **Segment**，此时数据可见（近实时）。
    
	3. **Translog**：为防丢数据，同时写事务日志。
    
	4. **Flush**：默认 30min，将 OS Cache 里的数据持久化到磁盘并清空 Translog。
	
	> 这是 ES 高性能的核心逻辑。**Refresh** 操作将内存中的文档构建成 Lucene 段（Segment），由于是在操作系统缓存中，所以避免了磁盘 IO。**Translog** 保证了断电不丢数据。**Flush**（默认 30min）执行真正的 `fsync` 刷盘并清空日志。这种“内存 -> 缓存 -> 磁盘”的分层设计，支撑了海量数据的快速写入。

### Q003：ES 是如何实现“分布式”的？Master 节点和 Data 节点的分工？

- **简答**：通过集群状态管理。Master 负责元数据和分片调度；Data 负责数据存储、读写与聚合。

- **深度解析**：
	- ES 采用对等架构，任何节点都能作为**协调节点（Coordinating Node）** 接收请求。Master 节点并不参与数据搜索（除非也是 Data 节点），从而避免了单点瓶颈。**架构建议**：生产环境必须做到“角色分离”，即独立设置 3 台仅限 Master 的节点，确保集群拓扑的稳定性。 

	- **Master**：管理元数据、索引分片分配、集群状态同步。
    
	- **Data**：负责数据存储、读写、聚合计算。
    
	- **协调节点**：接收用户请求、分发查询并合并结果（Reduce）。

### Q004：为什么 ES 的分片（Shard）数量不宜设置得过多或过少？

- **简答**：过少导致单个分片巨大，恢复慢且无法发挥并发优势；过多会导致元数据压力大，搜索时线程切换频繁，降低性能。

- **深度解析**：
	- 每个分片本质是一个 Lucene 索引，占用文件句柄和内存。**实战经验**：建议单个分片大小保持在 **20GB - 40GB** 之间。搜索请求会分发到所有分片，如果分片过多，协调节点合并结果（Reduce 阶段）的开销会指数级增长。

	- **过少**：导致单个分片过大（超过 50GB），搬迁和恢复极慢。
    
	- **过多**：每个分片都是一个 Lucene 实例，占用大量 CPU 和内存；查询时需要扫描更多分片，导致查询延迟增加。

### Q005：什么是 ES 的“段合并（Segment Merge）”？为什么它会消耗性能？

- **简答**：为了优化搜索性能，ES 后台会将多个小 Segment 合并成大 Segment，并物理删除已标记删除的数据。

- **深度解析**：
	- 因为 Segment 是不可变的，删除操作只是标记。随着写入增加，小文件过多会拖慢搜索。合并过程涉及大量的磁盘 **IO 读写和 CPU 解压压缩**。在高写入压力的架构设计中，需要通过 `index.merge.scheduler.max_thread_count` 限制合并线程数，防止其抢占查询资源。
	
	- 大量小 Segment 会拖慢搜索速度。ES 后台会定期合并。由于合并涉及**磁盘读取、压缩、解压、重新写入**，是典型的 IO 密集型操作。在高并发写入场景，常需要通过限速策略优化合并压力。

### Q006：解释 ES 的“词典压缩”算法：FST (Finite State Transducer)。

- **简答**：一种有限状态机转换器，将 Term 词典压缩至极小并常驻内存。

- **深度解析**：相比 Hash 或 Tree 结构，FST 利用了单词的前缀和后缀共性进行路径压缩。它能让数亿级别的词条索引驻留在内存中。**架构价值**：这使得搜索时无需进行磁盘 IO 即可快速定位到倒排链的位置，是 ES 实现毫秒级响应的底层基石。

### Q007：ES 在查询时，Filter 和 Query 有什么区别？

- **简答**：Query 计算相关性得分（Score），不可缓存；Filter 只判断“是否匹配”，且结果会被缓存到内存中。
    
- **深度解析**： Filter 不涉及复杂的空间向量模型计算，性能极高。在架构实践中，**对于范围查询（Range）或精确匹配（Term），务必使用 Filter**，这能极大地利用 Bitset 缓存减少计算量。

### Q008：如何处理 ES 的深度分页？（Scroll vs Search After）

- **简答**：`from+size` 超出 1 万条会报错。Scroll 适合全量导出；Search After 适合实时分页。
    
- **深度解析**： `from+size` 在深分页时，协调节点需要收集各分片返回的数据进行全局排序，极易导致 **OOM**。**Search After** 利用上一页最后一条记录的唯一值作为游标，不占用堆内存，是实现海量数据实时翻页的标准方案。

### Q009：什么是 ES 的 Mapping 爆炸？如何防止？

- **简答**：字段数过多（默认上限 1000）导致元数据同步变慢。
    
- **深度解析**： 如果开启动态映射且业务 Key 不规范，会产生大量垃圾字段。**对策**：1. 严禁开启 `dynamic: true`；2. 对不确定的字段使用 `flattened` 类型；3. 提前定义好 Index Template。

### Q010：ES 聚合查询（Aggregations）的原理及其对内存的挑战。

- **简答**：利用 Doc Values（正排索引）在内存中进行计算。
    
- **深度解析**： Doc Values 默认开启且基于磁盘存储，但聚合时需要将其加载到 OS Cache。如果是对 Text 字段（Fielddata）进行聚合，会全量加载到 JVM 堆，极易引发 **GC 甚至 OOM**。架构设计中应尽量避免对 Text 字段直接聚合。

### Q011：为什么 ES 不适合做频繁的更新操作？

- **简答**：因为段是不可变的，更新本质是“标记删除+插入新文档”。
    
- **深度解析**： 频繁更新会产生大量逻辑删除的文档，导致磁盘空间膨胀和搜索效率下降，直到段合并发生。在架构选型时，如果业务是**频繁更新且对事务要求高**，应优先使用 MySQL 而非 ES。

### Q012：什么是 ES 的“脑裂”，7.x 版本的集群选主机制如何优化了它？

- **简答**：网络分区导致一个集群出现两个 Master。7.x 引入了 Raft 风格的选主算法（Cluster State Storage）。
    
- **深度解析**： 旧版本依赖 `minimum_master_nodes` 参数，配置不当极易脑裂。新版本将投票机制自动化，节点会自动记录谁投了谁，确保在分区发生时，只有获得多数派支持的节点能成为 Master，彻底解决了配置陷阱。

### Q013：如何优化 ES 的写入速度？

- **简答**：使用 Bulk 批量操作、增加 Refresh 间隔、初始导入禁用副本。
    
- **深度解析**：
    
    1. **Bulk**：减少网络往返。2. **Refresh**：设为 30s 甚至 -1（导入期间），减少段生成次数。3. **副本**：写入时 `number_of_replicas: 0`，写完再开启。4. **内存**：给 `indices.memory.index_buffer_size` 预留足够空间。
### Q014：ES 里的 `nested` 对象和 `parent-child` 关联有什么区别？

- **简答**：Nested 存储在同一个 Lucene 文档内（查询快，更新慢）；Parent-Child 是独立文档（查询慢，更新快）。
    
- **深度解析**： Nested 对象修改其中一个字段需要重写整个文档。Parent-Child（Join 类型）适合子文档频繁变动且数量庞大的场景。**架构建议**：优先反规范化（数据冗余），其次 Nested，最后才考虑 Join。

### Q015：什么是 ES 的“冷热架构（Hot-Warm Architecture）”？

- **简答**：根据数据时效性将索引存放在不同性能的硬件上。
    
- **深度解析**： 热节点使用 SSD，存放最近 7 天数据；冷节点使用 HDD，存放历史数据。利用 `box_type` 标签配合索引生命周期管理（ILM），实现数据的自动平移，在保证性能的同时极大降低存储成本。

### Q016：ES 监控中最重要的指标有哪些？

- **简答**：集群状态（Green/Yellow/Red）、JVM 堆占用、GC 次数、线程池拒绝（Rejected）。
    
- **深度解析**： **Rejected** 尤其重要，它代表查询或写入压力已经超过了线程池上限，是系统需要扩容或优化的最直接信号。其次是段数量，段过多说明合并跟不上写入。

---

## 四、MQ消息队列

### Q001：RocketMQ 如何实现本地事务与消息发送的原子性？

- **回答方式一（二阶段流）**：发“半消息”到 Broker（对消费者不可见）→ 执行本地事务 → 发 Commit/Rollback。Broker 没收到确认会回查事务状态，实现最终一致性。
    
- **回答方式二（合同草稿流）**：先给邮局寄草稿，邮局扣下。事办成了打个电话让邮局发，办砸了让邮局撕。邮局没接到电话会主动打给你问情况。

### Q002：RocketMQ 的消息过滤（Tag vs SQL92）是在哪一端完成的？为什么 SQL92 过滤会损耗性能？

- **回答方式一（服务端开销流）**：Tag 过滤通常在服务端简单匹配，性能高；SQL92 在服务端执行复杂的表达式解析。由于需要解压消息头并进行布尔运算，会占用大量的 Broker CPU，因此高并发下需慎用。
    
- **回答方式二（安检门流）**：Tag 像看衣服颜色，瞄一眼就行（性能好）；SQL92 像开箱检查并填表（逻辑复杂），安检员（Broker）动作慢了，后面排队的包裹就堆积了。

### Q003：Kafka 是如何实现零拷贝（Zero-copy）的？

- **简答：** 利用 Linux 的 `sendfile` 系统调用。
    
- **深度解析：** 传统 IO 需要 4 次拷贝（磁盘->内核->用户->内核->网卡）。Kafka 通过 `sendfile` 直接将数据从内核缓冲区（Page Cache）拷贝到网卡，不经过用户空间。配合 **磁盘顺序写**，Kafka 的吞吐量能轻松达到网卡带宽上限。

### Q004：RocketMQ 怎么处理分布式事务？

- **简答：** 采用“半消息（Half Message）”机制。
    
- **深度解析：** 1. 发送半消息（对消费者不可见）； 2. 执行本地事务； 3. 根据本地事务结果 Commit 或 Rollback。如果超时，Broker 会**回查** Producer 状态。这种方式确保了本地数据库操作与消息发送的原子性。

### Q005：什么是消息队列的“幂等性”？业务上如何实现？

- **简答：** 无论消息消费多少次，结果都一样。
    
- **深度解析：** MQ 不保证不重复，只保证至少投递一次。**实战方案：** 1. **数据库唯一键：** 利用订单号等做唯一索引。 2. **状态机控制：** `UPDATE ... SET status=2 WHERE status=1`。 3. **去重表：** 在 Redis 中记录已处理过的消息 ID。

### Q006：为什么 Kafka 的性能远超 RabbitMQ？（存储架构的角度）

- **简答**：Kafka 采用**磁盘顺序写**、**零拷贝**和**页缓存（Page Cache）**技术，且分区（Partition）设计天然支持高并发；RabbitMQ 更多依赖内存和复杂的交换机（Exchange）逻辑。
    
- **深度解析**： Kafka 像是一个“巨大的追加日志文件”，每个分区就是一个顺序写入的磁盘空间，利用了磁盘顺序写性能接近内存的特性。而 RabbitMQ 在消息确认、死信处理、复杂的路由匹配上消耗了大量 CPU 资源。架构选型时：**海量数据流水选 Kafka，复杂业务逻辑、高实时性要求选 RabbitMQ/RocketMQ。**

### Q007：RocketMQ 的“半消息”是如何解决分布式事务的？

- **简答**：通过“先发消息、后执行事务、再确认”的流程，配合 Broker 的事务状态回查机制。
    
- **深度解析**：
    
    1. 生产者发送半消息，Broker 将其存入内部队列（消费者不可见）。
        
    2. 生产者执行本地数据库事务。
        
    3. 根据结果 Commit 或 Rollback。 **补偿机制**：如果确认消息丢失，Broker 会主动反向询问生产者该事务的最终状态。这确保了本地操作与消息通知的**原子性**，是实现最终一致性的标准方案。

### Q008：如何处理消息队列中的“重复消费”问题？（幂等性深度设计）

- **简答**：MQ 架构上只保证“至少投递一次”，不保证不重复。必须由业务端通过**唯一键约束**、**状态机**或**去重表**解决。
    
- **深度解析**：
    
    - **数据库唯一主键**：如支付订单号。
        
    - **乐观锁/状态机**：`update t set status=2 where id=1 and status=1`。
        
    - **分布式锁+Redis去重**：处理前先在 Redis 检查 `msgId`。 **架构建议**：幂等性是分布式系统的底线。与其追求 MQ 绝对不重发（代价太大），不如让下游具备“不怕重发”的能力。
### Q009：消息积压（Message Backlog）了，线上紧急处理方案是什么？

- **简答**：临时扩容消费者实例，并按比例增加 Topic 的分区（Partition）/队列数量。
    
- **深度解析**：
    
    1. **紧急处理**：新建一个 Topic，分区数设为原来的 10 倍，写一个临时 Consumer 将消息匀到新 Topic，再启动 10 倍的 Consumer 消费新 Topic。
        
    2. **排查根源**：是下游数据库慢了？还是 Consumer 代码有死循环？或是流量突增？ **注意**：在 Kafka 中，Consumer 数量受限于 Partition 数量，直接加机器而不加分区是无效的。

### Q010：Kafka 的 ISR、OSR、AR 分别代表什么？对可用性有什么影响？

- **简答**：AR 是所有副本，ISR 是同步中的副本，OSR 是落后的副本。
    
- **深度解析**： `AR = ISR + OSR`。Leader 选举只会在 **ISR** 列表中产生。 **架构影响**：如果设置 `acks = all`，只有当 ISR 中所有副本都写成功才会返回。如果 ISR 变小到只有一个（Leader 自己），系统可用性就会面临单点风险。

### Q011：为什么 RocketMQ 适合做金融级业务，而 Kafka 更多用于大数据？

- **简答**：RocketMQ 提供丰富的业务特性（如事务消息、延时消息、重试队列），且支持同步刷盘；Kafka 追求极致吞吐，设计上更简洁。
    
- **深度解析**： RocketMQ 借鉴了 Kafka 的思想但针对业务场景做了大量改造。其**订阅关系一致性**和**顺序消息**的保障比 Kafka 更细致。在大规模 Topic 下（如几万个），Kafka 的性能会因为随机 IO 剧降，而 RocketMQ 的 `CommitLog` 模式依然稳定。

### Q012：什么是消息队列的“死信队列（DLQ）”和“延时队列”？

- **简答**：死信队列存放多次重试失败的消息；延时队列让消息在指定时间后才被消费。
    
- **深度解析**： **死信**用于系统容错，需配合监控进行人工介入或补偿。**延时消息**常用于订单超时取消场景。RocketMQ 原生支持 18 个级别的延时，而 RabbitMQ 需要配合 TTL 和死信交换机（DLX）来实现。

### Q013：Kafka 的“零拷贝（Zero-copy）”技术到底减少了哪几次拷贝？

- **简答**：利用 `sendfile` 减少了数据从内核缓冲区到用户缓冲区，再从用户缓冲区写回内核缓冲区的 2 次拷贝和 2 次上下文切换。
    
- **深度解析**： 传统 IO：磁盘 -> 内核 Read Buffer -> 用户 Buffer -> Socket Buffer -> 网卡。 零拷贝：磁盘 -> 内核 Read Buffer -> 网卡。数据完全不经过 CPU 的“搬运”，效率极高。

### Q014：如何保证消息的顺序性？（全局顺序 vs 分区顺序）

- **简答**：通过分区键（Partition Key）将相关消息发送到同一个分区，且每个分区只有一个消费者线程。
    
- **深度解析**： 全局顺序在分布式下代价极大。通常业务只需要**分区顺序**（如同一个订单的操作是有序的）。生产者发送时指定 `orderId` 为 Key，Kafka 保证其落在同一个分片。注意：如果消费者内部开启了多线程并发处理，顺序性会被再次破坏，需在本地加锁或改为串行执行。

### Q015：消息丢失了怎么办？（生产者、Broker、消费者三维度分析）

- **简答**：
    
    - **生产者**：开启确认机制（acks=all），失败重试。
        
    - **Broker**：开启同步刷盘（RocketMQ）或多副本同步写入（Kafka）。
        
    - **消费者**：关闭自动提交 Offset，在业务处理完后再手动提交。
        
- **深度解析**： 数据可靠性与性能是天平的两端。在架构设计中，必须根据业务价值权衡。金融交易必须全链路确认，日志采集可以接受极小概率的丢失以换取高性能。

### Q016：RabbitMQ 的四种交换机（Exchange）模式及适用场景是什么？

- **简答**：Direct（直连）、Fanout（广播）、Topic（主题通配符）、Headers（头部匹配）。
    
- **深度解析**：
    
    - **Direct**：路由键（Routing Key）完全匹配，用于精准投递。
        
    - **Fanout**：无视路由键，转发给所有绑定队列，适用于实时广播（如配置更新）。
        
    - **Topic**：支持通配符（`#` 匹配多个词，`*` 匹配一个词），是**灵活业务路由**的核心。
        
    - **Headers**：不依赖路由键而依赖消息头的属性，性能较差，生产环境极少使用。
### Q017：什么是 Kafka 的 Rebalance 机制？如何避免频繁触发？

- **简答**：当消费者组内的成员发生变化（加入或退出）时，Partition 重新分配的过程。
    
- **深度解析**： Rebalance 期间会发生 **STW (Stop The World)**，导致消费停滞。 **优化方案**：
    
    1. **调大超时时间**：合理设置 `session.timeout.ms`（检测崩溃）和 `max.poll.interval.ms`（处理耗时）。
        
    2. **避免处理过慢**：如果单次 `poll` 数据过多处理不完，Kafka 会认为消费者挂了。
        
    3. **静态成员制**：Kafka 2.3+ 引入 `group.instance.id`，重启时不会触发重平衡。
### Q018：RocketMQ 的负载均衡算法与分区溢出策略是如何工作的？

- **简答**：默认采用“平均分配算法”，确保每个消费者分配到接近数量的队列。
    
- 深度解析：
    
    RocketMQ 的负载均衡是在客户端完成的。每个消费者会定时从 NameServer 获取 Topic 的路由信息，并对队列进行排序。溢出策略：如果消费者数量 > 队列数量，多出的消费者将处于空闲状态；反之，一个消费者会承担多个队列。
    
    架构提示：在扩容时，必须保证队列数 $\ge$ 消费者数，否则扩容机器无法分担压力。

### Q019：在分布式架构中，如何利用 MQ 实现“最终一致性”？

- **简答**：利用“本地消息表”或“事务消息”。
    
- **深度解析**： **本地消息表模式**：
    
    1. 将业务操作与“发送消息”动作放在同一个本地数据库事务中，写入一张 `message_log` 表。
        
    2. 后台定时任务扫描该表，确保消息成功发送到 MQ。
        
    3. 下游消费成功后反馈，删除该记录。 这种模式不依赖 MQ 的特殊功能，适合任何 MQ 选型。

### Q020：消息队列的“长轮询（Long Polling）”与“短轮询”有何差异？

- **简答**：短轮询频繁请求（空转浪费资源）；长轮询在服务端挂起请求，直到有新消息或超时才返回。
    
- **深度解析**： RocketMQ 默认使用长轮询。消费者请求 Broker，若没消息，Broker 保持连接 15s。这既保证了消息的**实时性**（消息一到立即返回），又避免了像短轮询那样频繁建立连接导致的 CPU 浪费。

### Q021：Kafka 的 Controller 节点是如何进行 Leader 选举的？

- **简答**：Controller 监听 ZooKeeper（或通过 KRaft 选举），负责分区的 Leader 切换。
    
- **深度解析**： 当一个分区的 Leader 宕机，Controller 会从该分区的 **ISR**（同步副本列表）中选出第一个存活的副本作为新 Leader。如果没有 ISR，则根据 `unclean.leader.election.enable` 配置决定是否允许 OSR（非同步副本）上位（这会导致数据丢失）。

### Q022：为什么说传统事务 MQ（如 ActiveMQ/JMS）在高并发下是瓶颈？

- **简答**：因为其严格遵循 JMS 规范，重度依赖内存状态和同步确认。
    
- **深度解析**： 传统 MQ 往往采用**中心化存储**和**复杂的 ACK 确认机制**，每发一条消息都要写索引、改状态。Kafka/RocketMQ 弃用了这些复杂逻辑，采用**分区并行**和**批量发送**，将单机瓶颈转化成了水平扩展的优势。

### Q023：如何实现海量定时任务？（时间轮算法 vs MQ 延时消息）

- **简答**：时间轮适合高精度、内存型任务；MQ 延时消息适合持久化、分布式任务。
    
- 深度解析：
    
    时间轮（Timing Wheel）：类似钟表，将任务挂在对应的刻度槽位， $O(1)$ 复杂度。
    
    架构建议：对于千万级的订单超时提醒，应优先使用 MQ 延时消息，因为 MQ 自带持久化和重试机制，防止系统重启导致任务丢失。

### Q024：什么是“背压（Backpressure）”机制，在 MQ 消费中如何体现？

- **简答**：当下游处理不动时，反向压制上游的发送速率，防止崩溃。
    
- **深度解析**： 在 Kafka 中，消费者通过控制 `poll` 的频率和数量来实现背压。如果业务逻辑处理变慢，`poll` 的间隔会自动拉长，Broker 就不会继续向该消费者推数据。这是一种**自我保护机制**，防止消费者因为内存溢出（OOM）而宕机。

### Q025：云原生架构下，Pulsar 这种“计算存储分离”的消息系统有何优势？

- **简答**：扩容时不需要搬迁数据，秒级伸缩。
    
- **深度解析**： Kafka 的 Partition 绑定在物理 Broker 上，扩容需搬迁 TB 级数据，极慢。Pulsar 存储层是独立的 BookKeeper 节点，Broker 只是无状态的服务层。扩容 Broker 瞬间完成，扩容存储层也只需新节点加入，不影响存量数据。这是**云原生架构**最理想的 MQ 选型。


---

## 五、NoSQL

### Q001：MongoDB 的分片集群（Sharding）如何选择片键（Shard Key）？

- **简答：** 选择高基数、分布均匀且常用的查询字段。
    
- **深度解析：** 片键直接决定了数据的分布。如果选择时间戳（递增），会导致“尾部热点”，所有新数据都写到同一个分片。应选择具有良好散列性的字段，或者使用**哈希分片**来平衡集群压力。

### Q002：MongoDB 的 WiredTiger 引擎相比旧引擎好在哪？

- **深度解析**：引入了 **文档级锁**（以前是库级或集合级锁）、数据压缩以及更高效的 Cache 算法，极大提升了并发写入性能。

### Q003：什么是 MongoDB 的“副本集（Replica Set）”选举机制？

- **简答**：通过 Raft 协议变种实现自动故障转移。
    
- **深度解析**：
    
    多数派（Majority）节点在线时方可选举。节点通过心跳监控 Primary 状态，一旦主节点失效，Secondary 节点根据优先级和 Oplog 同步进度发起投票。

### Q004：MongoDB 写入确认（Write Concern）有哪些级别？

- **深度解析**：`w: 1`（写主成功即回）、`w: majority`（大多数成功才回，最安全）、`j: true`（等日志落盘）。

### Q005：为什么 MongoDB 适合存储地理位置数据（GeoSpatial）？

- **深度解析**：原生支持 `2dsphere` 索引和 `$near` 运算符。其底层利用 **GeoHash** 将二维坐标转为一维字符串，极大地加快了“附近的人”这种查询。

### Q006：什么是 MongoDB 的“工作集（Working Set）”？

- **深度解析**：指系统经常访问的数据和索引。如果 Working Set 超过内存大小，会导致严重的磁盘换入换出（Page Fault），性能骤降。

### Q007：MongoDB 如何处理事务？（4.0 以后版本）

- **深度解析**：支持多文档酸（ACID）事务，通过全局逻辑时钟保证分布式环境下的一致性，但建议尽量通过嵌入式文档（Embedding）设计规避跨表事务。

### Q008：嵌入（Embedding）与引用（Referencing）如何选型？

-  **深度解析**：1:1 或数据量小的 1:N 选嵌入；数据量大或经常独立查询的 1:N 选引用。

### Q009：什么是 Oplog？它的幂等性体现在哪？

- **深度解析**：类似 Binlog，记录数据变更。它是幂等的，这意味着即使重复应用同一个 Oplog 条目，结果也保持不变。

### Q010：MongoDB 的集合关联查询 `$lookup` 性能如何？

- **深度解析**：类似于关系型数据库的左外连接。在大规模数据下，性能远不如 MySQL Join，架构上应优先考虑反规范化设计。

### Q011：如何定位 MongoDB 的性能瓶颈？

- **深度解析**：利用 `db.currentOp()` 查看运行中的请求，使用 `mongostat` 和 `mongotop` 实时监控 IO 压力。





